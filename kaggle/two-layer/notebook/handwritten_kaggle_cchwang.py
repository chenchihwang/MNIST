# -*- coding: utf-8 -*-
"""handwritten-kaggle-cchwang

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XKt8xjcEOsIiLzVYYB-77ycLrGtCZiue
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

digit_recognizer_path = kagglehub.competition_download('digit-recognizer')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

os.listdir(digit_recognizer_path)

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""The beginning of code written by Chen-Chi Hwang to classify the MNIST dataset using a simple two layer NN."""

# reading data in
file_path = os.path.join(digit_recognizer_path, 'train.csv')
df = pd.read_csv(file_path)
# print(df.head())

data = df.to_numpy()

m, n = data.shape
print(m, n)

np.random.shuffle(data)

data_dev = data[0:1000].T
Y_dev = data_dev[0]
X_dev = data_dev[1:n]
X_dev = X_dev / 255.

data_train = data[1000:m].T
Y_train = data_train[0]
X_train = data_train[1:n]
X_train = X_train / 255.
image_dim,m_train = X_train.shape

print(image_dim, m_train)

def init():
    W1 = np.random.rand(20, 784) - 0.5
    b1 = np.random.rand(20, 1) - 0.5
    W2 = np.random.rand(10, 20) - 0.5
    b2 = np.random.rand(10, 1) - 0.5
    return W1, b1, W2, b2

def relu(Z_1):
  A_1 = np.maximum(Z_1, 0)
  return A_1

def softmax(Z_2):
    exp_values = np.exp(Z_2)
    sum_exp = np.sum(exp_values, axis=0, keepdims=True)
    A_2 = exp_values / sum_exp
    return A_2

def feedfoward(W1, b1, W2, b2, X):
  Z_1 = W1.dot(X) + b1
  A_1 = relu(Z_1)
  Z_2 = W2.dot(A_1) + b2
  A_2 = softmax(Z_2)
  return Z_1, A_1, Z_2, A_2

def relu_prime(Z_1):
  return Z_1 > 0

def one_hot(Y):
  one_hot_Y = np.zeros((Y.size, Y.max() + 1))
  one_hot_Y[np.arange(Y.size), Y] = 1
  one_hot_Y = one_hot_Y.T
  return one_hot_Y

def backprop(Z_1, A_1, Z_2, A_2, W2, X, Y):
  one_hot_Y = one_hot(Y)
  dZ_2 = A_2 - one_hot_Y
  dW2 = (1 / m) * dZ_2.dot(A_1.T)
  db2 = (1 / m) * np.sum(dZ_2)
  dZ_1 = W2.T.dot(dZ_2) * relu_prime(Z_1)
  dW1 = (1 / m) * dZ_1.dot(X.T)
  db1 = (1 / m) * np.sum(dZ_1)
  return dW1, db1, dW2, db2

def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):
  W1 = W1 - alpha * dW1
  b1 = b1 - alpha * db1
  W2 = W2 - alpha * dW2
  b2 = b2 - alpha * db2
  return W1, b1, W2, b2

def get_predictions(A2):
    return np.argmax(A2, 0)

def get_accuracy(predictions, Y):
    print(predictions, Y)
    return np.sum(predictions == Y) / Y.size

def gradient_descent(X, Y, alpha, iterations):
  W1, b1, W2, b2 = init()
  for i in range(iterations):
    Z_1, A_1, Z_2, A_2 = feedfoward(W1, b1, W2, b2, X)
    dW1, db1, dW2, db2 = backprop(Z_1, A_1, Z_2, A_2, W2, X, Y)
    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)
    if i % 50 == 0:
      print("Iteration: ", i)
      print(get_accuracy(get_predictions(A_2), Y))
  return W1, b1, W2, b2

W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)

from matplotlib import pyplot as plt

def inference(X, W1, b1, W2, b2):
    _, _, _, A2 = feedfoward(W1, b1, W2, b2, X)
    return get_predictions(A2)

def test_inference(index, W1, b1, W2, b2):
    current_image = X_train[:, index, None]
    prediction = inference(X_train[:, index, None], W1, b1, W2, b2)
    label = Y_train[index]
    print("Prediction: ", prediction)
    print("Label: ", label)

    current_image = current_image.reshape((28, 28)) * 255
    plt.gray()
    plt.imshow(current_image, interpolation='nearest')
    plt.show()

test_inference(0, W1, b1, W2, b2)
test_inference(1, W1, b1, W2, b2)
test_inference(2, W1, b1, W2, b2)
test_inference(3, W1, b1, W2, b2)

get_accuracy(inference(X_dev, W1, b1, W2, b2), Y_dev)

